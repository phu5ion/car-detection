{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Car_Detection.ipynb","private_outputs":true,"provenance":[{"file_id":"1LfEwmp5SM0q8gEPILqM-dwMMN9XMH4UI","timestamp":1645435664080}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CxmDMK4yupqg"},"source":["# Object Detection\n"]},{"cell_type":"markdown","metadata":{"id":"Sy553YSVmYiK"},"source":["This lab is similar to the previous lab, except now instead of printing out the bounding box coordinates, you can visualize these bounding boxes on top of the image!"]},{"cell_type":"markdown","metadata":{"id":"v4XGxDrCkeip"},"source":["## Setup\n"]},{"cell_type":"code","metadata":{"id":"6cPY9Ou4sWs_"},"source":["# For running inference on the TF-Hub module.\n","import tensorflow as tf\n","\n","import tensorflow_hub as hub\n","\n","# For downloading the image.\n","import matplotlib.pyplot as plt\n","import tempfile\n","from six.moves.urllib.request import urlopen\n","from six import BytesIO\n","\n","# For drawing onto the image.\n","import numpy as np\n","from PIL import Image\n","from PIL import ImageColor\n","from PIL import ImageDraw\n","from PIL import ImageFont\n","from PIL import ImageOps\n","\n","# For measuring the inference time.\n","import time\n","\n","import os\n","\n","# Print Tensorflow version\n","print(tf.__version__)\n","\n","# Check available GPU devices.\n","print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"metadata":{"id":"kfHO-zpTr7Jj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Important: Modify the cwd to the folder where your car video is"],"metadata":{"id":"CE004ZF3o8as"}},{"cell_type":"code","source":["##########################\n","##########################\n","####### MODIFY THIS ######\n","##########################\n","##########################\n","\n","# This is the path to the folder containing the video\n","cwd = \"gdrive/MyDrive/Colab Notebooks/Car Detection/\"\n","\n","# This is the video name + extension\n","car_video_name = 'sample_car_video.mp4'\n","\n","# This is the number of frames per second for video slicing\n","FPS = 5\n","\n","# This is the (x1, y1) and (x2, y2) points connecting the left and right guiding lines\n","# y (0 = top, 1 = bottom)\n","# x (0 = left, 1 = right)\n","leftline = [(0.25, 1), (0.53, 0.5)]\n","rightline = [(0.85, 1), (0.53, 0.5)]"],"metadata":{"id":"hxn0ktqXo7T1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"Zd6UNsDjEvTv"}},{"cell_type":"markdown","metadata":{"id":"t-VdfLbC1w51"},"source":["### Select and load the model\n","As in the previous lab, you can choose an object detection module. Here are two that we've selected for you:\n","* [ssd + mobilenet V2](https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2) small and fast.\n","* [FasterRCNN + InceptionResNet V2](https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1): high accuracy"]},{"cell_type":"code","metadata":{"id":"uazJ5ASc2_QE"},"source":["# you can switch the commented lines here to pick the other model\n","\n","# ssd mobilenet version 2\n","# module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\"\n","\n","# You can choose inception resnet version 2 instead\n","module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xRVwVr40grw6"},"source":["#### Load the model\n","\n","Next, you'll load the model specified by the `module_handle`.\n","- This will take a few minutes to load the model."]},{"cell_type":"code","metadata":{"id":"MsFSuo2Wgrw6"},"source":["model = hub.load(module_handle)\n","detector = model.signatures['default']"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def resize_image(filename, new_width=640, new_height=360, display=False):\n","    '''\n","    Resizes an image and saves it locally.\n","    \n","    Args:\n","        filename (string) -- filename of the image\n","        new_width (int) -- size in pixels used for resizing the width of the image\n","        new_height (int) -- size in pixels used for resizing the length of the image\n","        \n","    Returns:\n","        (string) -- path to the saved image\n","    '''\n","    \n","    # opens the image\n","    pil_image = Image.open(filename)\n","    \n","    # resizes the image. will crop if aspect ratio is different.\n","    pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n","    \n","    # converts to the RGB colorspace\n","    pil_image_rgb = pil_image.convert(\"RGB\")\n","    \n","    # saves the image to the temporary file created earlier\n","    pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n","    \n","    print(\"Image downloaded to %s.\" % filename)\n","    \n","    if display:\n","        display_image(pil_image)\n","\n","    return filename"],"metadata":{"id":"Q93nSMWSuGY2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nAunxsz8grw6"},"source":["### Draw bounding boxes\n","\n","To build on what you saw in the previous lab, you can now visualize the predicted bounding boxes, overlaid on top of the image.  \n","- You can use `draw_boxes` to do this.  It will use `draw_bounding_box_on_image` to draw the bounding boxes."]},{"cell_type":"code","metadata":{"id":"J5rUpPPqgrw7"},"source":["def draw_bounding_box_on_image(image,\n","                               ymin,\n","                               xmin,\n","                               ymax,\n","                               xmax,\n","                               color,\n","                               font,\n","                               thickness=1,\n","                               display_str_list=()):\n","\n","    \"\"\"\n","    Adds a bounding box to an image.\n","    \n","    Args:\n","        image -- the image object\n","        ymin -- bounding box coordinate\n","        xmin -- bounding box coordinate\n","        ymax -- bounding box coordinate\n","        xmax -- bounding box coordinate\n","        color -- color for the bounding box edges\n","        font -- font for class label\n","        thickness -- edge thickness of the bounding box\n","        display_str_list -- class labels for each object detected\n","    \n","    \n","    Returns:\n","        No return.  The function modifies the `image` argument \n","                    that gets passed into this function\n","    \n","    \"\"\"\n","    draw = ImageDraw.Draw(image)\n","    im_width, im_height = image.size\n","    \n","    # scale the bounding box coordinates to the height and width of the image\n","    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n","                                ymin * im_height, ymax * im_height)\n","    \n","    # define the four edges of the detection box\n","    draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n","             (left, top)],\n","            width=thickness,\n","            fill=color)\n","\n","    # If the total height of the display strings added to the top of the bounding\n","    # box exceeds the top of the image, stack the strings below the bounding box\n","    # instead of above.\n","    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n","    # Each display_str has a top and bottom margin of 0.05x.\n","    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n","\n","    if top > total_display_str_height:\n","        text_bottom = top\n","    else:\n","        text_bottom = top + total_display_str_height\n","        \n","    # Reverse list and print from bottom to top.\n","    for display_str in display_str_list[::-1]:\n","        text_width, text_height = font.getsize(display_str)\n","        margin = np.ceil(0.05 * text_height)\n","        draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n","                        (left + text_width, text_bottom)],\n","                       fill=color)\n","        draw.text((left + margin, text_bottom - text_height - margin),\n","                  display_str,\n","                  fill=\"black\",\n","                  font=font)\n","        text_bottom -= text_height - 2 * margin\n","\n","\n","def draw_line(image,\n","                               points,\n","                               color,\n","                               thickness=1):\n","\n","    \"\"\"\n","    Adds a bounding box to an image.\n","    \n","    Args:\n","        image -- the image object\n","        points -- coordinates for the points\n","        color -- color for the bounding box edges\n","        thickness -- edge thickness of the line\n","    \n","    \n","    Returns:\n","        No return.  The function modifies the `image` argument \n","                    that gets passed into this function\n","    \n","    \"\"\"\n","    draw = ImageDraw.Draw(image)\n","    im_width, im_height = image.size\n","\n","    [(xmin, ymin), (xmax, ymax)] = points\n","    xmin *= im_width\n","    xmax *= im_width\n","    ymin *= im_height\n","    ymax *= im_height\n","    \n","    # define the four edges of the detection box\n","    draw.line([(xmin, ymin), (xmax, ymax)],\n","            width=thickness,\n","            fill=color)\n","    \n","def findbound(y, line):\n","  ''' Finds the x coordinate on the given line\n","  [(0.25, 1), (0.53, 0.5)]'''\n","\n","  [(x1, y1), (x2, y2)] = line\n","\n","  if y < y2 or y > y1:\n","    return -1\n","\n","  proportion = float(y-y1)/(y2-y1)\n","\n","  return x1 + proportion*(x2-x1)\n","\n","def draw_boxes(image, boxes, class_names, scores, max_boxes=100, min_score=0.3, showlines = False):\n","    \"\"\"\n","    Overlay labeled boxes on an image with formatted scores and label names.\n","    \n","    Args:\n","        image -- the image as a numpy array\n","        boxes -- list of detection boxes\n","        class_names -- list of classes for each detected object\n","        scores -- numbers showing the model's confidence in detecting that object\n","        max_boxes -- maximum detection boxes to overlay on the image (default is 10)\n","        min_score -- minimum score required to display a bounding box\n","        showlines (bool) -- boolean of whether to show the guiding lines\n","    \n","    Returns:\n","        image -- the image after detection boxes and classes are overlaid on the original image.\n","    \"\"\"\n","    colors = list(ImageColor.colormap.values())\n","\n","    try:\n","        font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n","                              10)\n","    except IOError:\n","        print(\"Font not found, using default font.\")\n","        font = ImageFont.load_default()\n","\n","    for i in range(min(boxes.shape[0], max_boxes)):\n","\n","        # filter out only some categories\n","        if class_names[i].decode(\"ascii\").lower() not in \\\n","        [\"car\", \"van\", \"motorcycle\", \"bicycle\", \"bus\"]: continue\n","        \n","        # only display detection boxes that have the minimum score or higher\n","        if scores[i] >= min_score:\n","            ymin, xmin, ymax, xmax = tuple(boxes[i])     \n","            image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n","\n","            # draw guiding lines\n","            if showlines:\n","              draw_line(image_pil,\n","                            points = leftline,\n","                              color = \"blue\")\n","              \n","              draw_line(image_pil,\n","                            points = rightline,\n","                              color = \"blue\")\n","              \n","            # filter out only boxes within the guiding lines\n","            leftbound = findbound(ymin, line = leftline)\n","            rightbound = findbound(ymin, line = rightline)\n","\n","            display_str = str(class_names[i].decode(\"ascii\"))\n","\n","            # distance formula from the paper\n","            height = (ymax - ymin)\n","            width = (xmax - xmin)\n","            # dist = 0.00540 *(2021.256 - 1.276714 * height - 0.6042361 * width + 0.0004751 * height * width)\n","            dist = 0.5/width\n","\n","            if xmax < leftbound or xmin > rightbound or leftbound == -1 or rightbound == -1: \n","              color = 'white'\n","            else:\n","              color = 'yellow'\n","              display_str += f\" {dist:.1f}m\"\n","\n","            # draw one bounding box and overlay the class labels onto the image\n","            draw_bounding_box_on_image(image_pil,\n","                                       ymin,\n","                                       xmin,\n","                                       ymax,\n","                                       xmax,\n","                                       color = color,\n","                                       font = font,\n","                                       display_str_list=[display_str])\n","            np.copyto(image, np.array(image_pil))\n","        \n","    return image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r5rVOWRSgrw7"},"source":["### run_detector\n","\n","This function will take in the object detection model `detector` and the path to a sample image, then use this model to detect objects.\n","- This time, run_dtector also calls `draw_boxes` to draw the predicted bounding boxes."]},{"cell_type":"code","metadata":{"id":"twlQG6TPgrw7"},"source":["def load_img(path):\n","    '''\n","    Loads a JPEG image and converts it to a tensor.\n","    \n","    Args:\n","        path (string) -- path to a locally saved JPEG image\n","    \n","    Returns:\n","        (tensor) -- an image tensor\n","    '''\n","    \n","    # read the file\n","    img = tf.io.read_file(path)\n","    \n","    # convert to a tensor\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    \n","    return img\n","\n","\n","def run_detector(detector, path, showlines = False, verbose = True):\n","    '''\n","    Runs inference on a local file using an object detection model.\n","    \n","    Args:\n","        detector (model) -- an object detection model loaded from TF Hub\n","        path (string) -- path to an image saved locally\n","        showlines (bool) -- boolean of whether to show the guiding lines\n","        verbose (bool) -- boolean of whether to print out number of objects found and inference time\n","    '''\n","    \n","    # load an image tensor from a local file path\n","    img = load_img(path)\n","\n","    # add a batch dimension in front of the tensor\n","    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n","    \n","    # run inference using the model\n","    start_time = time.time()\n","    result = detector(converted_img)\n","    end_time = time.time()\n","\n","    # save the results in a dictionary\n","    result = {key:value.numpy() for key,value in result.items()}\n","\n","    # print results\n","    if verbose:\n","      print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n","      print(\"Inference time: \", end_time-start_time)\n","    \n","    # draw predicted boxes over the image\n","    image_with_boxes = draw_boxes(\n","      img.numpy(), result[\"detection_boxes\"],\n","      result[\"detection_class_entities\"], result[\"detection_scores\"])\n","\n","    return image_with_boxes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Segment the video into frames!"],"metadata":{"id":"D0ax-T7GyZeS"}},{"cell_type":"code","source":["# Segment video into frames\n","import cv2\n","from os import makedirs\n","from os.path import splitext, dirname, basename, join\n","\n","def save_frames(video_path: str, frame_dir: str, fps:int = FPS,\n","                name=\"image\", ext=\"jpg\"):\n","    cap = cv2.VideoCapture(video_path)\n","    if not cap.isOpened():\n","        return\n","    if frame_dir[-1:] == \"\\\\\" or frame_dir[-1:] == \"/\":\n","        frame_dir = dirname(frame_dir)\n","    \n","    makedirs(frame_dir, exist_ok=True)\n","    base_path = join(frame_dir, name)\n","\n","    idx = 0\n","    while cap.isOpened():\n","        idx += 1\n","        ret, frame = cap.read()\n","        if ret:\n","            if cap.get(cv2.CAP_PROP_POS_FRAMES) == 1:  #Save 0 second frame\n","                cv2.imwrite(\"{}_{}.{}\".format(base_path, \"0000\", ext),\n","                            frame)\n","            elif idx*fps < cap.get(cv2.CAP_PROP_FPS):\n","                continue\n","            else:  #Save frames 1 second at a time\n","                second = int(cap.get(cv2.CAP_PROP_POS_FRAMES)/idx)\n","                filled_second = str(second).zfill(4)\n","                cv2.imwrite(\"{}_{}.{}\".format(base_path, filled_second, ext),\n","                            frame)\n","                idx = 0\n","        else:\n","            break\n","\n","save_frames(cwd+car_video_name, cwd+car_video_name.split('.')[0])"],"metadata":{"id":"_rtVptN7ycD_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TyB3hroOgrw7"},"source":["### Run the detector on the sliced video images!"]},{"cell_type":"code","source":["image_folder = cwd + car_video_name.split('.')[0]\n","images = sorted([img for img in os.listdir(image_folder) if img.endswith(\".jpg\")])\n","\n","dir_name = cwd+car_video_name.split('.')[0]+\"/processed/\"\n","if not os.path.exists(dir_name):\n","  os.mkdir(dir_name)\n","\n","for i, sliced_img in enumerate(images):\n","  image_path = resize_image(cwd+car_video_name.split('.')[0]+'/'+sliced_img)\n","  processed_img = run_detector(detector, image_path, showlines = False, verbose = False)\n","  # save and display the image\n","  plt.imshow(processed_img)\n","\n","  plt.imsave(dir_name+str(i).zfill(4)+'.jpg', processed_img)"],"metadata":{"id":"ahoT96LQvFRl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Test the code on one single image"],"metadata":{"id":"-bh20xdEVCbm"}},{"cell_type":"code","source":["# image_folder = cwd + car_video_name.split('.')[0]\n","# image_num = 35\n","# images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")][image_num]\n","\n","# image_path = resize_image(cwd+car_video_name.split('.')[0]+'/'+images)\n","# processed_img = run_detector(detector, image_path, showlines = False, verbose = False)\n","# # save and display the image\n","# plt.imshow(processed_img)\n","\n","# plt.imsave(dir_name+str(image_num).zfill(4)+'.jpg', processed_img)"],"metadata":{"id":"4lVsw4ASVEI8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Create the output video! (Video will be in same folder as the original video)"],"metadata":{"id":"q_hOSgIQ7W5R"}},{"cell_type":"code","source":["# Stitch video together\n","import cv2\n","import os\n","\n","processed_image_folder = cwd + car_video_name.split('.')[0] + \"/processed/\"\n","video_name = cwd + 'stitched_'+car_video_name.split('.')[0]+'.avi'\n","images = sorted([img for img in os.listdir(processed_image_folder) if img.endswith(\".jpg\")])\n","frame = cv2.imread(os.path.join(processed_image_folder, images[0]))\n","height, width, layers = frame.shape\n","video = cv2.VideoWriter(video_name, 0, FPS, (width,height))\n","\n","for image in images:\n","    video.write(cv2.imread(os.path.join(processed_image_folder, image)))\n","\n","cv2.destroyAllWindows()\n","video.release()"],"metadata":{"id":"-P1w4ePmwk27"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"tk0R7oGEuKHj"},"execution_count":null,"outputs":[]}]}